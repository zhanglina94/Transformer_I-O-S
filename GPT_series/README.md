# GPT  Series papers List

### 1.GPT 

2018_Improving Language Understanding by Generative Pre-Training

PaperÔºöradford2018improving.pdf (ubc.ca)
CodeÔºö
GitHub - huggingface/pytorch-openai-transformer-lm: üê•A PyTorch implementation of OpenAI's finetuned transformer language model with a script to import the weights pre-trained by OpenAI


### 2.GPT2

2019_Language Models are Unsupervised Multitask Learners

Paper:Language Models are Unsupervised Multitask Learners (d4mucfpksywv.cloudfront.net)
Code:GitHub - openai/gpt-2: Code for the paper "Language Models are Unsupervised Multitask Learners"

### 3.GPT3

2020_Language Models are Few-Shot Learners

Paper:1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf (neurips.cc)
Code :GitHub - EleutherAI/gpt-neox: An implementation of model parallel autoregressive transformers on GPUs, based on the DeepSpeed library.

### 4.ImageGPT

2020_Generative Pretraining from Pixels
Paper:Generative Pretraining from Pixels (openai.com)
Code:GitHub - openai/image-gpt


### 5.Decision Transformer
